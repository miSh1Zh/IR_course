\section{Описание решения}

\subsection{Архитектура системы}

Разработанная система информационного поиска состоит из следующих компонентов:

\begin{enumerate}
    \item \textbf{Краулер (Python + Scrapy)} --- сбор документов из интернет-источников
    \item \textbf{База данных (MongoDB)} --- хранение сырых документов и метаданных
    \item \textbf{Индексатор (C++)} --- построение инвертированного индекса
    \item \textbf{Поисковый движок (C++)} --- выполнение булевых запросов
    \item \textbf{Веб-интерфейс (Flask)} --- пользовательский интерфейс для поиска
\end{enumerate}

\begin{verbatim}
┌─────────────┐     ┌──────────┐     ┌───────────┐
│   Источники │────▶│ Краулер  │────▶│  MongoDB  │
│   (3 сайта) │     │ (Scrapy) │     │  (NoSQL)  │
└─────────────┘     └──────────┘     └─────┬─────┘
                                           │
                                           ▼
                    ┌──────────┐     ┌───────────┐
                    │ Индекс   │◀────│ Индексатор│
                    │ (binary) │     │   (C++)   │
                    └────┬─────┘     └───────────┘
                         │
                         ▼
┌──────────┐       ┌──────────┐
│   Web    │◀─────▶│ Searcher │
│ (Flask)  │       │  (C++)   │
└──────────┘       └──────────┘
\end{verbatim}

\subsection{Выбор источников данных}

\begin{enumerate}
    \item \textbf{journaldoctor.ru} --- научно-практический медицинский рецензируемый журнал, входящий в перечень ВАК (категория К1) и индексируемый в Scopus. Издаётся с 2002 года, содержит статьи по кардиологии, неврологии, педиатрии, эндокринологии и другим медицинским специальностям. Рекурсивный обход с глубиной 7.
    
    \item \textbf{b-news.media/science} --- научно-популярный раздел журнала биотехнологической компании BIOCAD. Публикует статьи о разработке лекарств, генной терапии, иммунологии, онкологии. Извлечение контента через meta-теги (og:title, og:description).
    
    \item \textbf{rmj.ru} --- Русский медицинский журнал, профессиональное издание для врачей. Содержит обзорные статьи, клинические рекомендации, результаты исследований по всем медицинским специальностям. Навигация по категориям (неврология, кардиология, эндокринология и др.).
\end{enumerate}

Выбор источников обусловлен следующими критериями:
\begin{itemize}
    \item Наличие большого количества научных статей (более 10,000 на каждый источник)
    \item Структурированная разметка (заголовки, категории, даты)
    \item Доступность существующих поисковиков для сравнения
    \item Единая тематическая область (медицина)
\end{itemize}

\subsection{Технологический стек}

Для сбора корпуса использовались следующие технологии:

\begin{itemize}
    \item \textbf{Scrapy} --- профессиональный фреймворк для веб-краулинга на Python, обеспечивающий асинхронную обработку запросов, управление rate limiting, обработку ошибок и интеграцию с базами данных.
    
    \item \textbf{MongoDB} --- документо-ориентированная NoSQL база данных для хранения статей. Выбрана за гибкость схемы и эффективное хранение текстовых данных.
    
    \item \textbf{Docker} --- контейнеризация с персистентными volumes для обеспечения сохранности данных при перезапуске контейнеров.
    
    \item \textbf{C++} --- язык реализации поискового движка с ограничением использования STL (только vector и string).
\end{itemize}

\subsection{Архитектура краулера}

Краулер реализован как модульная система из независимых spider'ов в Scrapy:

\begin{verbatim}
crawler/
├── medical_crawler/
│   ├── spiders/
│   │   ├── journaldoctor.py  # Рекурсивный обход
│   │   ├── bnews.py          # Meta-теги
│   │   └── rmj.py            # По категориям
│   ├── items.py        # Структура документа
│   ├── pipelines.py    # Сохранение в MongoDB
│   └── settings.py     # Конфигурация
├── crawl_all.sh        # Запуск всех spider'ов
└── scrapy.cfg
\end{verbatim}

Каждый spider отвечает за один источник, что обеспечивает:
\begin{itemize}
    \item Независимый запуск и отладку
    \item Адаптацию под специфику каждого сайта
    \item Параллельный сбор из нескольких источников
\end{itemize}

\subsection{Теоретические основы индексации}

\subsubsection{Инвертированный индекс}

Инвертированный индекс --- структура данных, сопоставляющая каждому терму список документов, в которых он встречается (posting list).

\begin{verbatim}
терм1 -> [doc_1, doc_5, doc_12, ...]
терм2 -> [doc_2, doc_3, doc_7, ...]
\end{verbatim}

Преимущества:
\begin{itemize}
    \item Быстрый поиск по термам: O(1) для хеш-таблицы
    \item Эффективные булевы операции на отсортированных списках
    \item Компактное хранение (delta-кодирование)
\end{itemize}

\subsubsection{Токенизация}

Токенизация --- процесс разбиения текста на отдельные лексемы (токены). 
В данной работе используется следующий алгоритм:
\begin{enumerate}
    \item Проход по тексту посимвольно (с учётом UTF-8)
    \item Выделение последовательностей букв (латиница + кириллица)
    \item Приведение к нижнему регистру
\end{enumerate}

\subsubsection{Стемминг}

Стемминг --- приведение слова к его основе путём удаления окончаний и суффиксов.

Для русского языка используется упрощённый алгоритм на основе списка окончаний:
\begin{verbatim}
-ость, -ами, -ому, -ого, -ать, -ять, ...
\end{verbatim}

Для английского языка --- упрощённая версия алгоритма Портера.

\subsubsection{Закон Ципфа}

Закон Ципфа утверждает, что частота слова обратно пропорциональна его рангу:

\[
f(r) = \frac{C}{r^\alpha}
\]

где $r$ --- ранг слова, $f(r)$ --- его частота, $\alpha \approx 1$.

В логарифмическом масштабе это даёт линейную зависимость:
\[
\log f = \log C - \alpha \cdot \log r
\]

\subsubsection{Булевы операции}

\textbf{AND (пересечение)} --- алгоритм слияния двух отсортированных списков:
\begin{verbatim}
intersect(L1, L2):
    result = []
    i, j = 0, 0
    while i < len(L1) and j < len(L2):
        if L1[i] == L2[j]:
            result.add(L1[i])
            i++, j++
        elif L1[i] < L2[j]: i++
        else: j++
    return result
\end{verbatim}

Сложность: O(|L1| + |L2|)

\textbf{OR (объединение)} --- аналогичный алгоритм, добавляющий элементы из обоих списков.

\textbf{NOT (отрицание)} --- перебор всех документов с исключением указанных.

\pagebreak

